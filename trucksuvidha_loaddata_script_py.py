# -*- coding: utf-8 -*-
"""TruckSuvidha_Loaddata_Script.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ovxqQhIi6_2Zz2JRrq6XlCiO-dkICCM8
"""

!pip install schedule
import pandas as pd
import datetime
import os
import schedule
import time
import matplotlib.pyplot as plt
from geopy.geocoders import Nominatim
import geopy.extra.rate_limiter

def collect_and_store_data():
    # Fetches data from the website and stores it with a timestamp.
    tables = pd.read_html('https://trucksuvidha.com/')
    df = tables[0]
    # Get current timestamp
    timestamp = datetime.datetime.now().strftime("%Y/%m/%d_%H:%M:%S")
    # Add timestamp column to DataFrame
    df['timestamp'] = timestamp
    # File to store the data
    file_path = '/content/trucksuvidha_data.csv'
    # If file exists, append data. Otherwise, create and write data with header.
    if os.path.exists(file_path):
        df.to_csv(file_path, mode='a', header=False, index=False)
    else:
        df.to_csv(file_path, mode='w', header=True, index=False)
    print(f"Data collected and saved at {timestamp}")


def get_city_data(city_name):

    geolocator = Nominatim(user_agent="city_data_collector")
    geocode = geopy.extra.rate_limiter.RateLimiter(geolocator.geocode, min_delay_seconds=1)

    location = geocode(city_name)

    if location:
        latitude = location.latitude
        longitude = location.longitude
        # Population data is not always available, so handle the exception
        try:
            population = location.raw['extratags']['population']
        except KeyError:
            population = "Not available"

        return latitude, longitude, population
    else:
        return None, None, None



# Set the duration for data collection (e.g., 1 hour)
duration = 1/6  # in hours
end_time = datetime.datetime.now() + datetime.timedelta(hours=duration)

# Schedule the function to run every 10 minutes
schedule.every(10).minutes.do(collect_and_store_data)

while datetime.datetime.now() < end_time:
    schedule.run_pending()
    time.sleep(1)

# Data processing and plotting can be added here after the data collection loop
# ...

# Example: Dropping duplicates and saving to a new file
df = pd.read_csv('/content/trucksuvidha_data.csv')
df.drop_duplicates(inplace=True)
df.to_csv('/content/trucksuvidha_data_no_duplicates.csv', index=False)


# Example: Get unique destination cities and their counts
df = pd.read_csv('/content/trucksuvidha_data.csv')
unique_destinations = df['Destination City'].unique()
destination_counts = df['Destination City'].value_counts()

# Example: Collecting and storing city data
city_data = []
for city in df['Destination City'].unique():
    latitude, longitude, population = get_city_data(city)
    if latitude and longitude:
        city_data.append([city, latitude, longitude, population])

city_df = pd.DataFrame(city_data, columns=['City', 'Latitude', 'Longitude', 'Population'])
city_df.to_csv('/content/destination_data.csv', mode='w', header=True, index=False)

#Example: Plotting the distribution of values in each column
df = pd.read_csv('/content/trucksuvidha_data.csv')

for column in df.columns:
    if not pd.api.types.is_numeric_dtype(df[column]):
        plt.figure(figsize=(8, 6))
        value_counts = df[column].value_counts()

        # Filter values greater than 2%
        filtered_values = value_counts[value_counts / value_counts.sum() > 0.02]

        # Explode slices for better visibility
        explode = [0.05] * len(filtered_values)  # Adjust explosion value as needed

        plt.pie(filtered_values, labels=filtered_values.index, autopct='%1.1f%%',
                startangle=90, pctdistance=0.85, explode=explode)

        # Draw circle to make it a donut chart
        centre_circle = plt.Circle((0, 0), 0.70, fc='white')
        fig = plt.gcf()
        fig.gca().add_artist(centre_circle)

        plt.title(f'Distribution of {column} ')
        plt.tight_layout()  # Adjust layout to prevent labels from being cut off
        plt.show()